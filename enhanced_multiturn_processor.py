#!/usr/bin/env python3
"""
å¢å¼ºçš„å¤šè½®å¯¹è¯å¤„ç†å™¨ - åŒ…å«çœŸå®å†å²è°ƒç”¨è½¨è¿¹
åŸºäºsave_scenarioå’Œload_scenarioåŠŸèƒ½ï¼Œç”ŸæˆçœŸå®çš„å·¥å…·è°ƒç”¨å†å²
"""

import json
import csv
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from omegaconf import OmegaConf
from envs.tool_manager.qwen3_manager import QwenManager

class EnhancedMultiTurnProcessor:
    """å¢å¼ºçš„å¤šè½®å¯¹è¯å¤„ç†å™¨ï¼Œç”ŸæˆçœŸå®çš„å·¥å…·è°ƒç”¨è½¨è¿¹"""
    
    def __init__(self):
        # å‡½æ•°åæ˜ å°„ï¼šä»æ—§æ ¼å¼åˆ°æ–°æ ¼å¼
        self.function_mapping = {
            # FileSystemç›¸å…³
            'ls': 'file_system-ls',
            'pwd': 'file_system-pwd', 
            'cd': 'file_system-cd',
            'mkdir': 'file_system-mkdir',
            'touch': 'file_system-touch',
            'echo': 'file_system-echo',
            'cat': 'file_system-cat',
            'rm': 'file_system-rm',
            'mv': 'file_system-mv',
            'cp': 'file_system-cp',
            'find': 'file_system-find',
            'grep': 'file_system-grep',
            'tail': 'file_system-tail',
            'diff': 'file_system-diff',
            'wc': 'file_system-wc',
            'sort': 'file_system-sort',
            'du': 'file_system-du',
            'rmdir': 'file_system-rmdir',
            'load_scenario': 'file_system-load_scenario',
            'save_scenario': 'file_system-save_scenario',
        }
        
        # å‚æ•°åæ˜ å°„
        self.param_mapping = {
            'ls': {'a': 'show_hidden'},
            'cd': {'folder': 'folder'},
            'mkdir': {'dir_name': 'dir_name'},
            'touch': {'file_name': 'file_name'},
            'echo': {'content': 'content', 'file_name': 'file_name'},
            'cat': {'file_name': 'file_name'},
            'rm': {'file_name': 'file_name'},
            'mv': {'source': 'source', 'destination': 'destination'},
            'cp': {'source': 'source', 'destination': 'destination'},
            'find': {'path': 'path', 'name': 'name'},
            'grep': {'file_name': 'file_name', 'pattern': 'pattern'},
            'tail': {'file_name': 'file_name', 'lines': 'lines'},
            'diff': {'file_name1': 'file_name1', 'file_name2': 'file_name2'},
        }
        
        self.manager = None
    
    def create_qwen_manager(self):
        """åˆ›å»ºQwenManagerå®ä¾‹"""
        if self.manager is None:
            config = {
                'config_path': "/home/ma-user/work/RL-Factory/envs/configs/bfcl_mcp_tools.pydata",
                'mcp_mode': 'stdio',
                'enable_limiter': False,
                'enable_thinking': False,
                'tool_name_selected': [],
                'parallel_sse_tool_call': {
                    'is_enabled': False,
                    'num_instances': 1
                }
            }
            
            verl_config = OmegaConf.create(config)
            self.manager = QwenManager(verl_config)
            print(f"å·²åˆ›å»ºQwenManagerï¼ŒåŠ è½½äº†{len(self.manager.all_tools)}ä¸ªå·¥å…·")
        
        return self.manager
    
    def execute_tool(self, tool_name: str, args: dict) -> dict:
        """æ‰§è¡Œå•ä¸ªå·¥å…·å¹¶è¿”å›ç»“æœ"""
        response_content = f"""
<tool_call>
{{"name": "{tool_name}", "arguments": {json.dumps(args, ensure_ascii=False)}}}
</tool_call>
"""
        
        try:
            actions, results = self.manager.execute_actions([response_content])
            if results and len(results) > 0:
                return {
                    'success': True,
                    'result': results[0],
                    'action': actions[0] if actions else 'unknown'
                }
            else:
                return {
                    'success': False,
                    'error': 'No results returned'
                }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def parse_function_call(self, call_str: str) -> Tuple[str, dict]:
        """è§£æå‡½æ•°è°ƒç”¨å­—ç¬¦ä¸²ï¼Œè¿”å›å‡½æ•°åå’Œå‚æ•°"""
        # å¤„ç†ç±»ä¼¼ "ls(a=True)" çš„æ ¼å¼
        if '(' in call_str and ')' in call_str:
            func_name = call_str.split('(')[0].strip()
            params_str = call_str[call_str.find('(')+1:call_str.rfind(')')]
            
            # è§£æå‚æ•°
            params = {}
            if params_str.strip():
                # ç®€å•çš„å‚æ•°è§£æï¼ˆæ”¯æŒåŸºæœ¬ç±»å‹ï¼‰
                for param in params_str.split(','):
                    if '=' in param:
                        key, value = param.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        
                        # ç±»å‹è½¬æ¢
                        if value.lower() == 'true':
                            value = True
                        elif value.lower() == 'false':
                            value = False
                        elif value.isdigit():
                            value = int(value)
                        elif value.startswith("'") and value.endswith("'"):
                            value = value[1:-1]
                        elif value.startswith('"') and value.endswith('"'):
                            value = value[1:-1]
                        
                        params[key] = value
            
            return func_name, params
        else:
            return call_str, {}
    
    def convert_function_call(self, old_call: str) -> Tuple[str, dict]:
        """å°†æ—§æ ¼å¼çš„å‡½æ•°è°ƒç”¨è½¬æ¢ä¸ºæ–°æ ¼å¼"""
        func_name, params = self.parse_function_call(old_call)
        
        # æ˜ å°„å‡½æ•°å
        new_func_name = self.function_mapping.get(func_name, func_name)
        
        # æ˜ å°„å‚æ•°å
        new_params = {}
        if func_name in self.param_mapping:
            param_map = self.param_mapping[func_name]
            for old_key, value in params.items():
                new_key = param_map.get(old_key, old_key)
                new_params[new_key] = value
        else:
            new_params = params
        
        return new_func_name, new_params
    
    def simulate_multi_turn_execution(self, scenario_data: dict, golden_answers: List[List[str]]) -> List[dict]:
        """æ¨¡æ‹Ÿå¤šè½®æ‰§è¡Œè¿‡ç¨‹ï¼Œç”ŸæˆçœŸå®çš„è°ƒç”¨è½¨è¿¹"""
        manager = self.create_qwen_manager()
        
        # åŠ è½½åˆå§‹åœºæ™¯
        load_result = self.execute_tool('file_system-load_scenario', {'scenario': scenario_data})
        if not load_result['success']:
            print(f"åŠ è½½åœºæ™¯å¤±è´¥: {load_result['error']}")
            return []
        
        execution_history = []
        
        # æ‰§è¡Œæ¯ä¸€è½®çš„golden answers
        for turn_idx, turn_actions in enumerate(golden_answers):
            turn_history = {
                'turn_index': turn_idx,
                'actions': [],
                'scenario_after': None
            }
            
            print(f"\næ‰§è¡Œç¬¬{turn_idx + 1}è½®æ“ä½œ...")
            
            for action_str in turn_actions:
                print(f"  æ‰§è¡Œ: {action_str}")
                
                # è½¬æ¢å‡½æ•°è°ƒç”¨æ ¼å¼
                new_func_name, new_params = self.convert_function_call(action_str)
                
                # æ‰§è¡Œå·¥å…·
                result = self.execute_tool(new_func_name, new_params)
                
                action_record = {
                    'original_call': action_str,
                    'converted_call': f"{new_func_name}({new_params})",
                    'function_name': new_func_name,
                    'parameters': new_params,
                    'execution_result': result,
                    'success': result['success']
                }
                
                turn_history['actions'].append(action_record)
                
                if result['success']:
                    print(f"    æˆåŠŸ: {new_func_name}")
                else:
                    print(f"    å¤±è´¥: {result['error']}")
            
            # ä¿å­˜å½“å‰è½®ç»“æŸåçš„åœºæ™¯çŠ¶æ€
            save_result = self.execute_tool('file_system-save_scenario', {})
            if save_result['success']:
                turn_history['scenario_after'] = save_result
                print(f"  ç¬¬{turn_idx + 1}è½®ç»“æŸï¼Œåœºæ™¯å·²ä¿å­˜")
            
            execution_history.append(turn_history)
        
        return execution_history
    
    def generate_realistic_tool_trace(self, execution_history: List[dict], current_turn: int, questions: List[str]) -> str:
        """åŸºäºçœŸå®æ‰§è¡Œå†å²ç”Ÿæˆæ ‡å‡†å¯¹è¯æ ¼å¼çš„å·¥å…·è°ƒç”¨è½¨è¿¹"""
        trace_lines = []
        
        for turn_idx in range(current_turn):
            if turn_idx < len(execution_history):
                turn_data = execution_history[turn_idx]
                
                # æ·»åŠ ç”¨æˆ·é—®é¢˜
                if turn_idx < len(questions):
                    trace_lines.append(f"User: {questions[turn_idx]}")
                
                # æ·»åŠ åŠ©æ‰‹çš„å·¥å…·è°ƒç”¨
                assistant_calls = []
                for action in turn_data['actions']:
                    func_name = action['function_name']
                    params = action['parameters']
                    tool_call = f'<tool_call>{{"name": "{func_name}", "arguments": {json.dumps(params, ensure_ascii=False)}}}</tool_call>'
                    assistant_calls.append(tool_call)
                
                if assistant_calls:
                    trace_lines.append(f"Assistant: {' '.join(assistant_calls)}")
                
                # æ·»åŠ å·¥å…·æ‰§è¡Œç»“æœ
                for action in turn_data['actions']:
                    result = action['execution_result']
                    
                    if result['success'] and 'result' in result:
                        result_content = result['result']
                        if isinstance(result_content, list) and len(result_content) > 0:
                            tool_result = result_content[0]
                            if isinstance(tool_result, dict) and 'content' in tool_result:
                                content = tool_result['content']
                                # æ ¼å¼åŒ–è¾“å‡ºå†…å®¹ï¼Œä¿æŒå¯è¯»æ€§
                                if len(content) > 300:
                                    trace_lines.append(f"Tool: {content[:300]}...")
                                else:
                                    trace_lines.append(f"Tool: {content}")
                    else:
                        trace_lines.append(f"Tool: Error - {result.get('error', 'Unknown error')}")
                
                trace_lines.append("")  # è½®æ¬¡ä¹‹é—´çš„åˆ†éš”
        
        return '\n'.join(trace_lines)
    
    def generate_realistic_tool_trace_with_results(self, execution_history: List[dict], current_turn: int) -> str:
        """åŸºäºçœŸå®æ‰§è¡Œå†å²ç”ŸæˆåŒ…å«ç»“æœçš„å·¥å…·è°ƒç”¨è½¨è¿¹"""
        trace_lines = []
        
        for turn_idx in range(current_turn):
            if turn_idx < len(execution_history):
                turn_data = execution_history[turn_idx]
                
                # æ·»åŠ è½®æ¬¡æ ‡é¢˜
                trace_lines.append(f"Turn {turn_idx + 1} execution:")
                
                for action in turn_data['actions']:
                    func_name = action['function_name']
                    params = action['parameters']
                    result = action['execution_result']
                    
                    # æ ¼å¼åŒ–è°ƒç”¨
                    if params:
                        param_strs = []
                        for key, value in params.items():
                            if isinstance(value, str):
                                param_strs.append(f"{key}='{value}'")
                            else:
                                param_strs.append(f"{key}={value}")
                        call_str = f"{func_name}({', '.join(param_strs)})"
                    else:
                        call_str = f"{func_name}()"
                    
                    trace_lines.append(f"  Call: {call_str}")
                    
                    # æ·»åŠ çœŸå®çš„æ‰§è¡Œç»“æœ
                    if result['success'] and 'result' in result:
                        result_content = result['result']
                        if isinstance(result_content, list) and len(result_content) > 0:
                            # æå–å·¥å…·æ‰§è¡Œç»“æœçš„å†…å®¹
                            tool_result = result_content[0]
                            if isinstance(tool_result, dict) and 'content' in tool_result:
                                content = tool_result['content']
                                # ç®€åŒ–æ˜¾ç¤ºï¼Œåªæ˜¾ç¤ºå…³é”®ä¿¡æ¯
                                if "successed" in content:
                                    # æå–ç»“æœéƒ¨åˆ†
                                    if "The result is:" in content:
                                        actual_result = content.split("The result is:")[-1].strip()
                                        trace_lines.append(f"  Result: {actual_result[:100]}{'...' if len(actual_result) > 100 else ''}")
                                    else:
                                        trace_lines.append(f"  Result: Success")
                                else:
                                    trace_lines.append(f"  Result: {content[:100]}{'...' if len(content) > 100 else ''}")
                    else:
                        trace_lines.append(f"  Result: Failed - {result.get('error', 'Unknown error')}")
                
                trace_lines.append("")  # ç©ºè¡Œåˆ†éš”
        
        return '\n'.join(trace_lines)
    
    def extract_scenario_from_save_result(self, save_result: dict) -> dict:
        """ä»save_scenarioç»“æœä¸­æå–åœºæ™¯æ•°æ®"""
        if save_result and save_result.get('success') and 'result' in save_result:
            result_content = save_result['result']
            if isinstance(result_content, list) and len(result_content) > 0:
                tool_result = result_content[0]
                if isinstance(tool_result, dict) and 'content' in tool_result:
                    content = tool_result['content']
                    # æŸ¥æ‰¾ "The result is:" åé¢çš„JSONå†…å®¹
                    if "The result is:" in content:
                        json_str = content.split("The result is:")[-1].strip()
                        try:
                            return json.loads(json_str)
                        except json.JSONDecodeError as e:
                            print(f"Failed to parse JSON from save_scenario result: {e}")
                            print(f"JSON string: {json_str[:200]}...")
        return None
    
    def process_document_pdf_scenario(self) -> dict:
        """å¤„ç†documentç›®å½•ä¸­PDFæ–‡ä»¶æ“ä½œçš„å¤šè½®åœºæ™¯"""
        # æ„å»ºdocumentåœºæ™¯æ•°æ®
        scenario_data = {
            "root": {
                "user": {
                    "type": "directory",
                    "contents": {
                        "document": {
                            "type": "directory",
                            "contents": {
                                "final_report.pdf": {
                                    "type": "file",
                                    "content": "Executive Summary\nThis report contains comprehensive analysis.\n\nBudget Analysis Section\nTotal budget: $100,000\nSpent: $75,000\nRemaining: $25,000\n\nBudget analysis shows favorable results.\nThe budget analysis indicates strong performance.\n\nConclusion\nProject is on track."
                                },
                                "previous_report.pdf": {
                                    "type": "file",
                                    "content": "Executive Summary\nThis is the previous quarterly report.\n\nBudget Analysis Section\nTotal budget: $90,000\nSpent: $70,000\nRemaining: $20,000\n\nBudget analysis from last quarter.\nThe budget analysis shows different trends.\n\nConclusion\nPrevious quarter results."
                                }
                            }
                        }
                    }
                }
            }
        }
        
        # Golden answersï¼ˆè½¬æ¢ä¸ºæ–°æ ¼å¼ï¼‰
        golden_answers = [
            ["file_system-cd(folder='document')", "file_system-mkdir(dir_name='temp')", "file_system-mv(source='final_report.pdf',destination='temp')"],
            ["file_system-cd(folder='temp')", "file_system-grep(file_name='final_report.pdf',pattern='budget analysis')"],
            ["file_system-sort()"],
            ["file_system-cd(folder='../document')", "file_system-mv(source='previous_report.pdf',destination='temp')", "file_system-cd(folder='temp')", "file_system-diff(file_name1='final_report.pdf',file_name2='previous_report.pdf')"]
        ]
        
        # é—®é¢˜åˆ—è¡¨
        questions = [
            "Move 'final_report.pdf' within document directory to 'temp' directory in document. Make sure to create the directory",
            "Perform a detailed search using grep to identify sections in the file pertaining to 'budget analysis'.",
            "Upon identifying the requisite 'budget analysis' content, sort the 'final_report.pdf' by line for improved clarity and comprehension.",
            "Move 'previous_report.pdf' in document directory to temp as well and having final report also there, proceed to juxtapose it with 'previous_report.pdf' to detect any critical alterations."
        ]
        
        print("="*60)
        print("å¤„ç†document PDFå¤šè½®åœºæ™¯")
        print("="*60)
        
        # æ¨¡æ‹Ÿæ‰§è¡Œ
        execution_history = self.simulate_multi_turn_execution(scenario_data, golden_answers)
        
        # ç”Ÿæˆå¢å¼ºçš„å•è½®æ•°æ®
        enhanced_data = []
        current_scenario = scenario_data  # åˆå§‹åœºæ™¯
        
        for turn_idx, question in enumerate(questions):
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œå°è¯•ä»å‰ä¸€è½®çš„scenario_afteræ›´æ–°åœºæ™¯
            if turn_idx > 0 and turn_idx-1 < len(execution_history):
                prev_turn = execution_history[turn_idx-1]
                if 'scenario_after' in prev_turn and prev_turn['scenario_after']:
                    updated_scenario = self.extract_scenario_from_save_result(prev_turn['scenario_after'])
                    if updated_scenario:
                        current_scenario = updated_scenario
                        print(f"  ç¬¬{turn_idx+1}è½®ä½¿ç”¨æ›´æ–°åçš„åœºæ™¯æ•°æ®")
            
            # æ„å»ºçœŸå®çš„å·¥å…·è°ƒç”¨è½¨è¿¹ï¼ˆç°åœ¨ä½¿ç”¨æ ‡å‡†å¯¹è¯æ ¼å¼ï¼ŒåŒ…å«å†å²ï¼‰
            tool_trace = ""
            if turn_idx > 0:
                tool_trace = self.generate_realistic_tool_trace(execution_history, turn_idx, questions) + "\n"
            
            # åˆ›å»ºprompt
            prompt_parts = []
            prompt_parts.append("System: # Tools\nYou may call one or more functions to assist with the user query.\nYou are provided with function signatures within <tools></tools> XML tags:\n<tools>\n{\"name\": \"get_weather\", \"description\": \"Get the weather of a city for a specific date.\", \"parameters\": {\" type\": \"object\", \"properties\": {\"city\": {\"type\": \"string\", \"description\": \"The city to get weather for,\nin Chinese.\"}, \"date\": {\"type\": \"string\", \"description\": \"The date in YYYY-MM-DD format.\"}}, \"required\": [\"city\"]}}\n</tools>\nFor each function call, output the function name and arguments within the following XML format:\n<tool_call>{\"name\": \"get_weather\", \"arguments\": {\"city\": \"Beijing\", \"date\": \"2025-08-24\"}}</tool_call>\nYou are a helpful assistant.")
            
            if tool_trace:
                prompt_parts.append(tool_trace)
            
            prompt_parts.append(f"User: {question}")
            
            # è·å–å½“å‰è½®çš„golden answers
            converted_golden_answers = []
            if turn_idx < len(golden_answers):
                for action_call in golden_answers[turn_idx]:
                    converted_golden_answers.append(action_call)
            
            enhanced_item = {
                "id": f"document_pdf_scenario_turn_{turn_idx}_0_enhanced",
                "question": question,
                "golden_answers": converted_golden_answers,
                "data_source": ["FileSystem"],
                "prompt": "\n".join(prompt_parts),
                "ability": "tool_use",
                "reward_model": "{'final state': {}, 'style': 'rule'}",
                "extra_info": {
                    "initial_config": {"FileSystem": current_scenario},
                    "path": ["GorillaFileSystem.cd", "GorillaFileSystem.mkdir", "GorillaFileSystem.mv", "GorillaFileSystem.grep", "GorillaFileSystem.sort", "GorillaFileSystem.diff"],
                    "original_id": "document_pdf_scenario",
                    "turn_index": turn_idx,
                    "question_index": 0,
                    "execution_history": execution_history[turn_idx] if turn_idx < len(execution_history) else None,
                    "realistic_trace": True
                }
            }
            
            enhanced_data.append(enhanced_item)
        
        return {
            'scenario_data': scenario_data,
            'execution_history': execution_history,
            'enhanced_data': enhanced_data
        }
    
    def process_multi_turn_base_1(self) -> dict:
        """å¤„ç†multi_turn_base_1ç¤ºä¾‹"""
        # multi_turn_base_1çš„åœºæ™¯æ•°æ®
        scenario_data = {
            "root": {
                "alex": {
                    "type": "directory",
                    "contents": {
                        "workspace": {
                            "type": "directory",
                            "contents": {
                                "log.txt": {
                                    "type": "file",
                                    "content": "This is a log file. No errors found. Another line. Yet another line. Error: Something went wrong. Final line."
                                },
                                "archive": {
                                    "type": "directory",
                                    "contents": {}
                                },
                                ".hidden_file": {
                                    "type": "file",
                                    "content": "This is a hidden file."
                                }
                            }
                        }
                    }
                }
            }
        }
        
        # Golden answersï¼ˆåŸå§‹æ ¼å¼ï¼‰
        golden_answers = [
            ["ls(a=True)"],  # Turn 0
            ["cd(folder='workspace')", "mv(source='log.txt',destination='archive')"],  # Turn 1
            ["cd(folder='archive')", "grep(file_name='log.txt',pattern='Error')"],  # Turn 2
            ["tail(file_name='log.txt',lines=20)"]  # Turn 3
        ]
        
        # é—®é¢˜åˆ—è¡¨
        questions = [
            "I am alex. Check if the current directory is under my name and list all the visible and hidden contents in the current directory now, please.",
            "Go to workspace directory and move one of the 'log.txt' files into a new directory 'archive'.",
            "Investigate within 'log.txt' for the occurrence of the keyword 'Error'.",
            "Finally, show the last 20 lines the file."
        ]
        
        print("="*60)
        print("å¤„ç†multi_turn_base_1ç¤ºä¾‹")
        print("="*60)
        
        # æ¨¡æ‹Ÿæ‰§è¡Œ
        execution_history = self.simulate_multi_turn_execution(scenario_data, golden_answers)
        
        # ç”Ÿæˆå¢å¼ºçš„å•è½®æ•°æ®
        enhanced_data = []
        current_scenario = scenario_data  # åˆå§‹åœºæ™¯
        
        for turn_idx, question in enumerate(questions):
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œå°è¯•ä»å‰ä¸€è½®çš„scenario_afteræ›´æ–°åœºæ™¯
            if turn_idx > 0 and turn_idx-1 < len(execution_history):
                prev_turn = execution_history[turn_idx-1]
                if 'scenario_after' in prev_turn and prev_turn['scenario_after']:
                    updated_scenario = self.extract_scenario_from_save_result(prev_turn['scenario_after'])
                    if updated_scenario:
                        current_scenario = updated_scenario
                        print(f"  ç¬¬{turn_idx+1}è½®ä½¿ç”¨æ›´æ–°åçš„åœºæ™¯æ•°æ®")
            
            # æ„å»ºçœŸå®çš„å·¥å…·è°ƒç”¨è½¨è¿¹ï¼ˆç°åœ¨ä½¿ç”¨æ ‡å‡†å¯¹è¯æ ¼å¼ï¼ŒåŒ…å«å†å²ï¼‰
            tool_trace = ""
            if turn_idx > 0:
                tool_trace = self.generate_realistic_tool_trace(execution_history, turn_idx, questions) + "\n"
            
            # åˆ›å»ºprompt
            prompt_parts = []
            prompt_parts.append("System: # Tools\nYou may call one or more functions to assist with the user query.\nYou are provided with function signatures within <tools></tools> XML tags:\n<tools>\n{\"name\": \"get_weather\", \"description\": \"Get the weather of a city for a specific date.\", \"parameters\": {\" type\": \"object\", \"properties\": {\"city\": {\"type\": \"string\", \"description\": \"The city to get weather for,\nin Chinese.\"}, \"date\": {\"type\": \"string\", \"description\": \"The date in YYYY-MM-DD format.\"}}, \"required\": [\"city\"]}}\n</tools>\nFor each function call, output the function name and arguments within the following XML format:\n<tool_call>{\"name\": \"get_weather\", \"arguments\": {\"city\": \"Beijing\", \"date\": \"2025-08-24\"}}</tool_call>\nYou are a helpful assistant.")
            
            if tool_trace:
                prompt_parts.append(tool_trace)
            
            prompt_parts.append(f"User: {question}")
            
            # è½¬æ¢golden answersåˆ°æ–°æ ¼å¼
            converted_golden_answers = []
            if turn_idx < len(golden_answers):
                for old_call in golden_answers[turn_idx]:
                    new_func_name, new_params = self.convert_function_call(old_call)
                    converted_golden_answers.append(f"{new_func_name}({json.dumps(new_params, separators=(',', ':'))})")
            
            enhanced_item = {
                "id": f"multi_turn_base_1_turn_{turn_idx}",
                "question": question,
                "golden_answers": converted_golden_answers,
                "data_source": ["FileSystem"],
                "prompt": "\n".join(prompt_parts),
                "ability": "tool_use",
                "reward_model": "{'final state': {}, 'style': 'rule'}",
                "extra_info": {
                    "initial_config": {"FileSystem": current_scenario},
                    "original_id": "multi_turn_base_1",
                    "turn_index": turn_idx,
                }
            }
            
            enhanced_data.append(enhanced_item)
        
        return {
            'scenario_data': scenario_data,
            'execution_history': execution_history,
            'enhanced_data': enhanced_data
        }
    
    def save_enhanced_data(self, enhanced_result: dict, output_file: str):
        """ä¿å­˜å¢å¼ºæ•°æ®åˆ°æ–‡ä»¶"""
        with open(output_file, 'w', encoding='utf-8') as f:
            for item in enhanced_result['enhanced_data']:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"å¢å¼ºæ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    def save_execution_history(self, execution_history: List[dict], output_file: str):
        """ä¿å­˜æ‰§è¡Œå†å²åˆ°æ–‡ä»¶"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(execution_history, f, indent=2, ensure_ascii=False)
        
        print(f"æ‰§è¡Œå†å²å·²ä¿å­˜åˆ°: {output_file}")

def fix_split_multiturn_to_single():
    """ä¿®æ­£split_multiturn_to_single.pyä¸­çš„å‡½æ•°è°ƒç”¨æ ¼å¼"""
    print("ä¿®æ­£split_multiturn_to_single.pyä¸­çš„å‡½æ•°è°ƒç”¨æ ¼å¼...")
    
    # è¯»å–åŸæ–‡ä»¶
    with open('/home/ma-user/work/RL-Factory/data/bfcl_data/split_multiturn_to_single.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å®šä¹‰éœ€è¦ä¿®æ­£çš„æ˜ å°„
    corrections = {
        # ç³»ç»Ÿæç¤ºè¯ä¸­çš„å·¥å…·æ ¼å¼ä¿®æ­£
        'Tools\\nYou may call one or more functions': '# Tools\\nYou may call one or more functions',
        
        # æ·»åŠ æ­£ç¡®çš„ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
        '"# You are a helpful assistant."': '''"""# Tools
You may call one or more functions to assist with the user query.
You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"name": "get_weather", "description": "Get the weather of a city for a specific date.", "parameters": {" type": "object", "properties": {"city": {"type": "string", "description": "The city to get weather for,\\nin Chinese."}, "date": {"type": "string", "description": "The date in YYYY-MM-DD format."}}, "required": ["city"]}}
</tools>
For each function call, output the function name and arguments within the following XML format:
<tool_call>{"name": "get_weather", "arguments": {"city": "Beijing", "date": "2025-08-24"}}</tool_call>
You are a helpful assistant."""'''
    }
    
    # åº”ç”¨ä¿®æ­£
    for old, new in corrections.items():
        content = content.replace(old, new)
    
    # ä¿å­˜ä¿®æ­£åçš„æ–‡ä»¶
    backup_file = '/home/ma-user/work/RL-Factory/data/bfcl_data/split_multiturn_to_single.py.backup'
    with open(backup_file, 'w', encoding='utf-8') as f:
        with open('/home/ma-user/work/RL-Factory/data/bfcl_data/split_multiturn_to_single.py', 'r', encoding='utf-8') as orig:
            f.write(orig.read())
    
    with open('/home/ma-user/work/RL-Factory/data/bfcl_data/split_multiturn_to_single.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"å·²ä¿®æ­£split_multiturn_to_single.pyï¼Œå¤‡ä»½ä¿å­˜åœ¨: {backup_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºçš„å¤šè½®å¯¹è¯å¤„ç†å™¨")
    print("="*80)
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = EnhancedMultiTurnProcessor()
    
    try:
        # å¤„ç†document PDFåœºæ™¯
        print("\n1. å¤„ç†document PDFå¤šè½®åœºæ™¯...")
        pdf_result = processor.process_document_pdf_scenario()
        
        # ä¿å­˜PDFåœºæ™¯ç»“æœ
        output_dir = Path('/home/ma-user/work/RL-Factory/data/enhanced_multiturn')
        output_dir.mkdir(exist_ok=True)
        
        pdf_enhanced_file = output_dir / 'document_pdf_scenario_enhanced.json'
        pdf_history_file = output_dir / 'document_pdf_scenario_execution_history.json'
        
        processor.save_enhanced_data(pdf_result, str(pdf_enhanced_file))
        processor.save_execution_history(pdf_result['execution_history'], str(pdf_history_file))
        
        # æ˜¾ç¤ºPDFåœºæ™¯ç¤ºä¾‹
        print("\n2. PDFåœºæ™¯å¢å¼ºæ•°æ®ç¤ºä¾‹:")
        if pdf_result['enhanced_data']:
            example = pdf_result['enhanced_data'][1]  # æ˜¾ç¤ºç¬¬äºŒè½®ï¼ˆæœ‰å†å²è®°å½•ï¼‰
            print(f"ID: {example['id']}")
            print(f"Question: {example['question']}")
            print(f"Golden Answers: {example['golden_answers']}")
            print("çœŸå®å·¥å…·è°ƒç”¨è½¨è¿¹é¢„è§ˆ:")
            if 'Previous tool calls:' in example['prompt']:
                trace_start = example['prompt'].find('Previous tool calls:')
                trace_part = example['prompt'][trace_start:trace_start+800]
                print(trace_part + "..." if len(trace_part) >= 800 else trace_part)
        
        # å¤„ç†multi_turn_base_1ç¤ºä¾‹
        print("\n3. å¤„ç†multi_turn_base_1ç¤ºä¾‹...")
        enhanced_result = processor.process_multi_turn_base_1()
        
        enhanced_file = output_dir / 'multi_turn_base_1_enhanced.json'
        history_file = output_dir / 'multi_turn_base_1_execution_history.json'
        
        processor.save_enhanced_data(enhanced_result, str(enhanced_file))
        processor.save_execution_history(enhanced_result['execution_history'], str(history_file))
        
        # ä¿®æ­£split_multiturn_to_single.py
        print("\n4. ä¿®æ­£split_multiturn_to_single.py...")
        fix_split_multiturn_to_single()
        
        print("\nâœ… å¤„ç†å®Œæˆï¼")
        print(f"PDFåœºæ™¯å¢å¼ºæ•°æ®æ–‡ä»¶: {pdf_enhanced_file}")
        print(f"PDFåœºæ™¯æ‰§è¡Œå†å²æ–‡ä»¶: {pdf_history_file}")
        print(f"Base1å¢å¼ºæ•°æ®æ–‡ä»¶: {enhanced_file}")
        print(f"Base1æ‰§è¡Œå†å²æ–‡ä»¶: {history_file}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
